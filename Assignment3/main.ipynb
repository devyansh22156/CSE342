{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Importing all the required libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54ca48feb5628af2"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:32.592358Z",
     "start_time": "2024-04-03T18:18:32.585422Z"
    }
   },
   "id": "ac829b0e1d8ed191"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Filtering the dataset according to required classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e4b6cfd7e4cb4ac"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Test and Train filtered data: \n",
      "(18623, 784)\n",
      "(3147, 784)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
    "response = requests.get(url)\n",
    "data = np.load(BytesIO(response.content))\n",
    " \n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']\n",
    "\n",
    "train_filter = np.where((y_train == 0) | (y_train == 1) | (y_train == 2))\n",
    "test_filter = np.where((y_test == 0) | (y_test == 1) | (y_test == 2))\n",
    "\n",
    "X_train = x_train[train_filter]\n",
    "Y_train = y_train[train_filter]\n",
    "X_test = x_test[test_filter]\n",
    "Y_test = y_test[test_filter]\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 784))\n",
    "X_test = X_test.reshape((X_test.shape[0], 784))\n",
    "\n",
    "print(\"Dimensions of Test and Train filtered data: \")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:38.913157Z",
     "start_time": "2024-04-03T18:18:32.695490Z"
    }
   },
   "id": "1430aeef6c2e3964"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Applying PCA on train dataset to obtain U matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "994106067255f7bf"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of U: \n",
      "(784, 18623)\n"
     ]
    }
   ],
   "source": [
    "X = X_train.T\n",
    "X_mean = np.mean(X, axis = 0)\n",
    "X_centre = X - X_mean\n",
    "S = np.dot(X_centre, X_centre.T)/(X_centre.shape[1]-1)\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(S)\n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "print(\"Dimensions of U: \")\n",
    "U = eigenvectors[:, idx]\n",
    "Y = np.dot(U.T, X_centre)\n",
    "print(Y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:42.679419Z",
     "start_time": "2024-04-03T18:18:38.942172Z"
    }
   },
   "id": "e26aa6b238fe1365"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a168a3aa1b634d73"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reducing features from 784 to 10 of Train and Test Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cd806372441cf81"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Up\n",
      "(784, 10)\n",
      "New Dimension of Train Dataset\n",
      "(18623, 10)\n",
      "New Dimension of Test Dataset\n",
      "(3147, 10)\n"
     ]
    }
   ],
   "source": [
    "p = 10\n",
    "Up = U[:, :p]\n",
    "print(\"Dimension of Up\")\n",
    "print(Up.shape)\n",
    "Yp = np.dot(Up.T, X_centre)\n",
    "X = Yp.T\n",
    "Xre_p = np.dot(Up, Yp) + X_mean\n",
    "print(\"New Dimension of Train Dataset\")\n",
    "print(X.shape)\n",
    "X_test = X_test.T\n",
    "X_test_centre = X_test - np.mean(X_test)\n",
    "Yp2 = np.dot(Up.T, X_test_centre)\n",
    "X_2 = Yp2.T\n",
    "print(\"New Dimension of Test Dataset\")\n",
    "print(X_2.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:43.499417Z",
     "start_time": "2024-04-03T18:18:42.706493Z"
    }
   },
   "id": "40755abb53739e7a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scatter plot of Train dataset where different color representing different classes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c11dd485b38775e"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = {}\n",
    "\n",
    "    def fit(self, features, classes):\n",
    "        self.tree = self.growTree(features, classes, depth=0)\n",
    "\n",
    "    def giniImpurity(self, Y):\n",
    "        classes = [0, 1, 2]\n",
    "        gini = 0\n",
    "        n = len(Y)\n",
    "        for element in classes:\n",
    "            p = np.sum(Y == element)/n\n",
    "            gini += p*(1-p)\n",
    "        return gini\n",
    "\n",
    "    def bestSplit(self, features, Y):\n",
    "        bestGini = float('inf')\n",
    "        bestSplitDim = None\n",
    "        threshold = None\n",
    "        \n",
    "        for dim in range(features.shape[1]):\n",
    "            values = np.unique(features[:, dim])\n",
    "            mini = np.min(values)\n",
    "            maxi = np.max(values)\n",
    "            for test in range(20):  \n",
    "                value = np.random.uniform(mini, maxi)  \n",
    "                leftIndices = features[:, dim] <= value\n",
    "                rightIndices = features[:, dim] > value\n",
    "                leftGini = self.giniImpurity(Y[leftIndices])\n",
    "                rightGini = self.giniImpurity(Y[rightIndices])\n",
    "\n",
    "                totalGini = (leftGini * np.sum(leftIndices) + rightGini * np.sum(rightIndices)) / len(Y)\n",
    "\n",
    "                if totalGini < bestGini:\n",
    "                    bestGini = totalGini\n",
    "                    bestSplitDim = dim\n",
    "                    threshold = value\n",
    "\n",
    "        return bestSplitDim, threshold\n",
    "\n",
    "    def growTree(self, features, Y, depth):\n",
    "        if depth == self.max_depth or len(np.unique(Y)) == 1:\n",
    "            return np.argmax(np.bincount(Y))\n",
    "        splitDim, threshold = self.bestSplit(features, Y)\n",
    "        leftIndices = features[:, splitDim] <= threshold\n",
    "        rightIndices = features[:, splitDim] > threshold\n",
    "        leftTree = self.growTree(features[leftIndices], Y[leftIndices], depth+1)\n",
    "        rightTree = self.growTree(features[rightIndices], Y[rightIndices], depth+1)\n",
    "        return {'splitDim': splitDim, 'threshold':threshold, 'left': leftTree, 'right': rightTree}\n",
    "\n",
    "    def predict(self, features):\n",
    "        pred = []\n",
    "        for x in features:\n",
    "            prediction = self.traverseTree(x, self.tree)\n",
    "            pred.append(prediction)\n",
    "        pred = np.array(pred)\n",
    "        return pred\n",
    "\n",
    "    def traverseTree(self, feature, tree):\n",
    "        if isinstance(tree, dict):\n",
    "            if feature[tree['splitDim']] <= tree['threshold']:\n",
    "                return self.traverseTree(feature, tree['left'])\n",
    "            else:\n",
    "                return self.traverseTree(feature, tree['right'])\n",
    "        else:\n",
    "            return tree\n",
    "\n",
    "tree = DecisionTree(2)\n",
    "tree.fit(X, Y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:43.900445Z",
     "start_time": "2024-04-03T18:18:43.509589Z"
    }
   },
   "id": "7f8b927db00deccb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing and Determining overall and classwise accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba3043a3730a8018"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction Vector [2 1 0 ... 0 1 2]\n",
      "Class 0 Accuracy: 90.82 %\n",
      "Class 1 Accuracy: 76.83 %\n",
      "Class 2 Accuracy: 93.31 %\n",
      "Total Accuracy: 86.59 %\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    for i in range(3):\n",
    "        class_indices = np.where(y_true == i)[0]  \n",
    "        real = np.sum(y_pred[class_indices] == i) \n",
    "        n = len(class_indices) \n",
    "        class_accuracy = (real/n)*100  \n",
    "        print(f\"Class {i} Accuracy: {class_accuracy:.2f} %\")\n",
    "    total_accuracy = np.mean(y_true==y_pred) * 100  \n",
    "    print(f\"Total Accuracy: {total_accuracy:.2f} %\")\n",
    "\n",
    "pred = tree.predict(X_2)\n",
    "print(\"prediction Vector\", pred)\n",
    "accuracy(Y_test, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:43.932291Z",
     "start_time": "2024-04-03T18:18:43.902552Z"
    }
   },
   "id": "bc24dd3781cb55ef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now applying Bagging on my Tree Model, Number of Dataset = 5 (with Replacement) and Printing the Overall and Classwise Accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd702f3d801ee592"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def createBaggedDatasets(X_train, Y_train):\n",
    "    baggedDatasets = []\n",
    "    for i in range(5):\n",
    "        indexes = np.random.choice(X_train.shape[0], size=X_train.shape[0]-100, replace=True)\n",
    "        X_temp = X_train[indexes]\n",
    "        Y_temp = Y_train[indexes]\n",
    "        baggedDatasets.append((X_temp, Y_temp))\n",
    "    return baggedDatasets\n",
    "\n",
    "def trainTrees(baggedDatasets):\n",
    "    trees = []\n",
    "    for X_temp, Y_temp in baggedDatasets:\n",
    "        tree = DecisionTree(2)\n",
    "        tree.fit(X_temp, Y_temp)\n",
    "        trees.append(tree)\n",
    "    return trees\n",
    "\n",
    "baggedDatasets = createBaggedDatasets(X, Y_train)\n",
    "trees = trainTrees(baggedDatasets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:45.515561Z",
     "start_time": "2024-04-03T18:18:43.946428Z"
    }
   },
   "id": "a7861f75fe83091a",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "totalPredictions = []\n",
    "\n",
    "for tree in trees:\n",
    "    predictions = tree.predict(X_2)\n",
    "    totalPredictions.append(predictions)\n",
    "totalPredictions = np.array(totalPredictions).T    \n",
    "\n",
    "pred = []\n",
    "for predictions in totalPredictions:\n",
    "    labelCounts = {}\n",
    "    for prediction in predictions:\n",
    "        if prediction in labelCounts:\n",
    "            labelCounts[prediction] += 1\n",
    "        else:\n",
    "            labelCounts[prediction] = 1\n",
    "    predictedClass = None\n",
    "    maxi = 0\n",
    "    for label, cnt in labelCounts.items():\n",
    "        if cnt>maxi:\n",
    "            predictedClass=label\n",
    "            maxi = cnt\n",
    "    if maxi>=3:\n",
    "        pred.append(predictedClass)\n",
    "    else:\n",
    "        pred.append(None)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:45.613193Z",
     "start_time": "2024-04-03T18:18:45.522109Z"
    }
   },
   "id": "7d79e00ac3defdb2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy: 93.06 %\n",
      "Class 1 Accuracy: 83.26 %\n",
      "Class 2 Accuracy: 84.98 %\n",
      "Total Accuracy: 86.88 %\n"
     ]
    }
   ],
   "source": [
    "def calculateAccuracy(y_true, y_pred):\n",
    "    class_acc = {}\n",
    "    for class_label in np.unique(y_true):\n",
    "        indexes = np.where(y_true==class_label)[0]\n",
    "        correct_predictions = np.sum(np.array(y_pred)[indexes]==class_label)\n",
    "        n = len(indexes)\n",
    "        class_acc[class_label] = (correct_predictions/n) * 100\n",
    "        print(f\"Class {class_label} Accuracy: {class_acc[class_label]:.2f} %\")\n",
    "    total_acc = np.mean(y_true == y_pred) * 100\n",
    "    print(f\"Total Accuracy: {total_acc:.2f} %\")\n",
    "    \n",
    "calculateAccuracy(Y_test, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T18:18:45.642534Z",
     "start_time": "2024-04-03T18:18:45.617498Z"
    }
   },
   "id": "600a4fba19af2709",
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
